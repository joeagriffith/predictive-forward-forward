{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pff.utils.dataset import PreloadedDataset\n",
    "from pff.nn.models import PFF\n",
    "from pff.optim import train_pff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])\n",
    "raw_dataset = dsets.MNIST(root='../Datasets/', train=True, transform=transform, download=False)\n",
    "\n",
    "# SUBSET_SIZE = 5000\n",
    "# raw_dataset = torch.utils.data.Subset(raw_dataset, range(SUBSET_SIZE))\n",
    "VAL_RATIO = 0.2\n",
    "length = len(raw_dataset) * 0.2\n",
    "n_val = int(length * VAL_RATIO)\n",
    "n_train = len(raw_dataset) - n_val\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(raw_dataset, [n_train, n_val])\n",
    "\n",
    "\n",
    "train_dset = PreloadedDataset.from_dataset(raw_dataset, None, device)\n",
    "val_dset = PreloadedDataset.from_dataset(raw_dataset, None, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [784, 2000, 2000, 2000, 10]\n",
    "model = PFF(sizes).to(device)\n",
    "stats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "# BATCH_SIZE = 2048\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 80\n",
    "LR = 0.001\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "stats = train_pff(\n",
    "    model,\n",
    "    train_dset,\n",
    "    BATCH_SIZE,\n",
    "    optimiser,\n",
    "    EPOCHS,\n",
    "    stats\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pff.utils.functions import my_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1343e+08, -2.4996e+09,  2.0125e+10, -1.0635e+10,  1.7235e+10,\n",
      "         -1.1003e+10,  3.4524e+09,  2.9326e+10, -2.9295e+10, -2.0506e+10,\n",
      "         -7.0953e+09,  7.0628e+09,  2.0914e+10,  2.7987e+10,  1.6781e+09,\n",
      "         -3.9245e+09,  1.6851e+10,  7.0713e+09, -2.6026e+10, -1.0132e+10],\n",
      "        [-4.0795e+09, -1.0186e+09,  5.2653e+09, -6.1755e+09,  2.0358e+10,\n",
      "         -1.4578e+10,  1.5307e+08,  2.4518e+10, -2.3845e+10, -1.9032e+10,\n",
      "         -3.3909e+08,  1.2529e+10,  2.0205e+10,  2.6395e+10, -6.6079e+09,\n",
      "         -4.4533e+09,  8.9984e+09,  1.7496e+10, -1.9924e+10, -2.6854e+09],\n",
      "        [-6.9687e+09,  1.1715e+09,  1.1888e+10,  2.1008e+09,  1.3598e+10,\n",
      "         -1.1218e+10,  3.2638e+09,  1.6608e+10, -2.4195e+10, -1.4288e+10,\n",
      "          4.0473e+08,  5.4200e+09,  1.5732e+10,  2.8169e+10,  4.5415e+09,\n",
      "         -3.6378e+09,  8.3780e+09,  1.1503e+10, -1.5220e+10, -5.8759e+09],\n",
      "        [ 3.5456e+08, -2.8794e+09,  1.9781e+10, -1.1755e+10,  1.7099e+10,\n",
      "         -1.1573e+10,  4.3872e+09,  3.0025e+10, -2.9910e+10, -2.0057e+10,\n",
      "         -8.1427e+09,  7.5663e+09,  2.1214e+10,  2.8353e+10,  1.8446e+09,\n",
      "         -3.6944e+09,  1.7079e+10,  7.6977e+09, -2.5316e+10, -1.0492e+10],\n",
      "        [-6.0204e+09,  3.3700e+08,  8.5514e+09, -3.5200e+09,  1.9775e+10,\n",
      "         -6.0057e+09,  1.7248e+09,  2.7254e+10, -1.5994e+10, -1.8951e+10,\n",
      "         -2.0271e+09,  1.2714e+10,  1.9281e+10,  2.3725e+10, -2.6231e+08,\n",
      "          1.9401e+09,  1.7167e+10,  1.5336e+10, -2.1595e+10, -9.3933e+09],\n",
      "        [-5.6765e+09,  1.2610e+09,  9.2392e+09, -3.7622e+09,  2.1106e+10,\n",
      "         -5.6860e+09,  2.2279e+09,  2.7095e+10, -1.5464e+10, -1.8749e+10,\n",
      "         -1.0769e+09,  1.2020e+10,  2.0159e+10,  2.3425e+10, -2.7475e+08,\n",
      "          2.1046e+09,  1.5517e+10,  1.4606e+10, -2.1779e+10, -8.1210e+09],\n",
      "        [-8.1763e+09,  1.2344e+09,  1.2831e+10,  2.5672e+09,  1.2961e+10,\n",
      "         -9.6740e+09,  3.1989e+09,  1.5868e+10, -2.3794e+10, -1.3236e+10,\n",
      "          1.1476e+09,  5.6968e+09,  1.6211e+10,  2.8447e+10,  3.4557e+09,\n",
      "         -4.4097e+09,  8.2471e+09,  1.1293e+10, -1.4703e+10, -4.0925e+09],\n",
      "        [-3.4403e+09,  3.0884e+09,  1.2152e+10, -5.7903e+09,  1.5038e+10,\n",
      "         -7.4504e+09,  5.2667e+09,  2.3006e+10, -2.8593e+10, -1.5058e+10,\n",
      "          4.7005e+09,  5.0142e+09,  1.7481e+10,  2.7745e+10,  5.2987e+09,\n",
      "         -3.6208e+09,  1.6578e+10,  1.6755e+10, -2.7890e+10, -3.6663e+09],\n",
      "        [-3.3933e+09,  4.2209e+09,  1.1466e+10, -5.6878e+09,  1.3924e+10,\n",
      "         -7.4088e+09,  5.7449e+09,  2.2978e+10, -2.7675e+10, -1.6424e+10,\n",
      "          4.7583e+09,  5.9514e+09,  1.7032e+10,  2.7956e+10,  5.4388e+09,\n",
      "         -3.6473e+09,  1.6955e+10,  1.7016e+10, -2.8709e+10, -3.5731e+09],\n",
      "        [ 3.2369e+09,  5.8530e+09,  1.0416e+10, -7.0858e+09,  1.5052e+10,\n",
      "         -1.3591e+10,  1.7932e+09,  2.1473e+10, -2.8070e+10, -1.4831e+10,\n",
      "          3.5175e+09,  1.0125e+10,  2.7863e+10,  2.1493e+10, -4.4836e+09,\n",
      "         -4.4819e+09, -2.2121e+08,  1.9316e+10, -2.1898e+10, -5.7830e+09],\n",
      "        [-4.2452e+09,  6.1831e+09,  1.8053e+10, -4.9428e+09,  1.1471e+10,\n",
      "         -1.0387e+10,  2.1271e+09,  2.0349e+10, -2.2745e+10, -1.8498e+10,\n",
      "         -5.9790e+08,  9.1646e+09,  1.5494e+10,  2.0296e+10,  4.8803e+09,\n",
      "         -1.1605e+10,  9.8410e+09,  1.3887e+10, -1.1002e+10, -1.1028e+10],\n",
      "        [-6.4187e+09,  1.4689e+09,  2.3528e+10, -3.0372e+09,  1.3649e+10,\n",
      "         -1.6528e+10,  4.4232e+09,  1.8624e+10, -2.0877e+10, -1.5469e+10,\n",
      "          7.2028e+09,  8.4911e+09,  1.4666e+10,  2.2239e+10, -2.7436e+09,\n",
      "         -1.0760e+09,  8.6215e+09,  1.5230e+10, -2.9306e+10, -1.2361e+10],\n",
      "        [-3.8039e+09,  4.2378e+09,  1.1790e+10, -5.8978e+09,  1.5060e+10,\n",
      "         -7.9180e+09,  4.8514e+09,  2.3414e+10, -2.8187e+10, -1.5863e+10,\n",
      "          4.8188e+09,  4.9814e+09,  1.7247e+10,  2.7878e+10,  5.3570e+09,\n",
      "         -3.2215e+09,  1.6900e+10,  1.7253e+10, -2.8805e+10, -3.8387e+09],\n",
      "        [-5.8393e+09, -6.2992e+08,  4.6113e+09, -5.8265e+09,  1.9896e+10,\n",
      "         -1.4856e+10,  5.5784e+08,  2.3955e+10, -2.3905e+10, -2.0330e+10,\n",
      "          1.0347e+09,  1.3284e+10,  2.0004e+10,  2.5667e+10, -6.8299e+09,\n",
      "         -5.1372e+09,  1.0040e+10,  1.8386e+10, -2.0624e+10, -3.3041e+09],\n",
      "        [-7.3114e+09,  4.8899e+08,  1.2299e+10,  1.9695e+09,  1.3085e+10,\n",
      "         -1.0782e+10,  3.7273e+09,  1.6306e+10, -2.4285e+10, -1.2754e+10,\n",
      "          1.0429e+09,  5.4958e+09,  1.6275e+10,  2.8154e+10,  3.6576e+09,\n",
      "         -4.3553e+09,  8.7145e+09,  1.1039e+10, -1.5281e+10, -4.4978e+09],\n",
      "        [-5.0192e+09, -1.6361e+09,  4.6929e+09, -7.0035e+09,  2.1213e+10,\n",
      "         -1.5160e+10,  9.4562e+07,  2.4896e+10, -2.3826e+10, -1.9270e+10,\n",
      "          5.1693e+08,  1.2967e+10,  2.0288e+10,  2.6404e+10, -5.9786e+09,\n",
      "         -4.6271e+09,  9.0918e+09,  1.6899e+10, -2.0717e+10, -3.5678e+09]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\joeag\\Documents\\predictive-forward-forward\\mnist.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m X, Y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataloader))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m Y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(Y, \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m infer_and_generate(model, X, Y)\n",
      "\u001b[1;32mc:\\Users\\joeag\\Documents\\predictive-forward-forward\\mnist.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# print(f\"step {i}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     y_hat, z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mstep_rep(x, y, z)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     x_hat, E, z_g \u001b[39m=\u001b[39m step_gen_model(z, z_g)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "G = nn.Linear(20, 100).to(device)\n",
    "def step_gen_layer(z_above):\n",
    "    z_above = F.normalize(z_above, dim=1)\n",
    "    return my_relu(G(z_above))\n",
    "\n",
    "def step_gen_model(z, z_g):\n",
    "    errors = []\n",
    "    z_g_bar = my_relu(z_g)\n",
    "    \n",
    "    z_above = z_g_bar\n",
    "    z_pred = step_gen_layer(z_above)\n",
    "    errors.append((z_pred - z[-1].detach()).square().sum(dim=1).mean())\n",
    "    \n",
    "    z_g.grad = None\n",
    "    errors[-1].backward(retain_graph=True)\n",
    "    with torch.no_grad():\n",
    "        print(z_g.grad)\n",
    "        z_g = z_g - 0.1 * z_g.grad\n",
    "    \n",
    "\n",
    "def infer_and_generate(model, x, y):\n",
    "    z = model.forward(x)\n",
    "    z_g = torch.zeros((x.shape[0], model.g_units), requires_grad=True).to(model.device)\n",
    "    z_g.retain_grad()\n",
    "\n",
    "    for i in range(5):\n",
    "        # print(f\"step {i}\")\n",
    "        y_hat, z = model.step_rep(x, y, z)\n",
    "        x_hat, E, z_g = step_gen_model(z, z_g)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dset, batch_size=16, shuffle=True)\n",
    "X, Y = next(iter(dataloader))\n",
    "Y = torch.nn.functional.one_hot(Y, 10).to(device)\n",
    "infer_and_generate(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\joeag\\Documents\\predictive-forward-forward\\mnist.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x_bar \u001b[39m=\u001b[39m my_relu(x\u001b[39m.\u001b[39mdetach())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m z \u001b[39m=\u001b[39m x_bar\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m z\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joeag/Documents/predictive-forward-forward/mnist.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.rand((1,), requires_grad=True)\n",
    "x_bar = my_relu(x.detach())\n",
    "z = x_bar.pow(2)\n",
    "z.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: torch.Size([200, 784]), torch.Size([200, 500]), torch.Size([200, 200]), torch.Size([200, 500])\n",
      "layer 1: torch.Size([500, 200]), torch.Size([500, 100]), torch.Size([500, 500]), torch.Size([500, 100])\n",
      "layer 2: torch.Size([100, 500]), torch.Size([100, 10]), torch.Size([100, 100]), torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"layer {i}: {layer.W.weight.shape}, {layer.V.weight.shape}, {layer.L.weight.shape}, {layer.G.weight.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
